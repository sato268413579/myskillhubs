"""
LangChain + LangGraph ã‚’ä½¿ç”¨ã—ãŸGemini APIãƒ™ãƒ¼ã‚¹ã®ãƒˆãƒ¬ãƒ³ãƒ‰èª¿æŸ»ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import os
from typing import Dict, List, Any
from datetime import datetime, date

# LangChain imports
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate

# LangGraph imports
from langgraph.graph import StateGraph, END
from typing_extensions import TypedDict

# Initialize Gemini AI
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    google_api_key=os.getenv("GEMINI_API_KEY"),
    temperature=0,
    convert_system_message_to_human=True
)

# LangGraph State Definition
class TrendResearchState(TypedDict):
    trend: str
    analysis_result: Dict[str, Any]
    final_result: Dict[str, Any]
    error_message: str

print("âœ… Gemini-based Trend Research Assistant with LangGraph initialized")

# LangGraph Node Functions
def analyze_trend_node(state: TrendResearchState) -> TrendResearchState:
    """
    LangGraphãƒãƒ¼ãƒ‰: Gemini APIã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’èª¿æŸ»ãƒ»åˆ†æ
    """
    trend = state["trend"]
    print(f"ğŸ¤– [LangGraph] Starting Gemini-based trend analysis for: {trend}")
    
    current_date = datetime.now()
    current_year = current_date.year
    current_month = current_date.strftime("%Yå¹´%mæœˆ")
    
    # Gemini APIãƒ™ãƒ¼ã‚¹èª¿æŸ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    analysis_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=f"""ã‚ãªãŸã¯{current_month}æ™‚ç‚¹ã§ã®æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰ã«é–¢ã™ã‚‹èª¿æŸ»ã®å°‚é–€å®¶ã§ã™ã€‚
æ³¨ç›®ã•ã‚Œã¦ã„ã‚‹æƒ…å ±ã‚’Webæ¤œç´¢ã‚’ç”¨ã„ã¦èª¿æŸ»ã™ã‚‹ã“ã¨ã‚’å¾—æ„ã¨ã—ã¾ã™ã€‚

å‡ºåŠ›å½¢å¼: ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„
{{
  "trend": "èª¿æŸ»å¯¾è±¡ã®ãƒˆãƒ¬ãƒ³ãƒ‰å",
  "summary": "è©³ç´°ãªMarkdownå½¢å¼ã®èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆå…¨æ–‡",
  "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰4", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰5"],
  "insights": [
    "é‡è¦ãªæ´å¯Ÿ1",
    "é‡è¦ãªæ´å¯Ÿ2",
    "é‡è¦ãªæ´å¯Ÿ3"
  ],
  "latest_developments": [
    "{current_year}å¹´ã®æœ€æ–°å‹•å‘1",
    "{current_year}å¹´ã®æœ€æ–°å‹•å‘2"
  ],
  "market_analysis": {{
    "current_status": "ç¾åœ¨ã®å¸‚å ´çŠ¶æ³",
    "growth_trend": "æˆé•·ãƒˆãƒ¬ãƒ³ãƒ‰",
    "key_players": ["ä¸»è¦ä¼æ¥­1", "ä¸»è¦ä¼æ¥­2"]
  }},
  "future_outlook": [
    "{current_year}å¹´ä»¥é™ã®å±•æœ›1",
    "{current_year}å¹´ä»¥é™ã®å±•æœ›2"
  ],
  "reliability_note": "ã“ã®åˆ†æã®ä¿¡é ¼æ€§ã¨æƒ…å ±æºã«é–¢ã™ã‚‹æ³¨è¨˜"
}}

å¿…ãšJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""),
        
        HumanMessage(content=f"""
èª¿æŸ»å¯¾è±¡: {trend}
ä¸Šè¨˜ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã«ã¤ã„ã¦ã€ç™ºè¡¨ã‚’å«ã‚ãŸæœ€æ–°æƒ…å ±ã‚’Webæ¤œç´¢ã‚’ç”¨ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚
        """)
    ])
    
    try:
        response = llm.invoke(analysis_prompt.format_messages())
        analysis_text = response.content.strip()
        
        # JSONã®æŠ½å‡ºã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if analysis_text.startswith("```"):
            analysis_text = analysis_text.strip("`")
            if analysis_text.startswith("json"):
                analysis_text = analysis_text[4:].strip()
        
        analysis = json.loads(analysis_text)
        state["analysis_result"] = analysis
        print("âœ… [LangGraph] Gemini analysis completed successfully")
        return state
        
    except json.JSONDecodeError as e:
        print(f"âŒ [LangGraph] JSON parsing error: {e}")
        state["error_message"] = f"åˆ†æçµæœã®JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}"
        state["analysis_result"] = create_fallback_analysis_dict(trend, state["error_message"])
        return state
    except Exception as e:
        print(f"âŒ [LangGraph] Analysis error: {e}")
        state["error_message"] = f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
        state["analysis_result"] = create_fallback_analysis_dict(trend, state["error_message"])
        return state

def finalize_result_node(state: TrendResearchState) -> TrendResearchState:
    """
    LangGraphãƒãƒ¼ãƒ‰: æœ€çµ‚çµæœã‚’ç”Ÿæˆ
    """
    trend = state["trend"]
    analysis_result = state["analysis_result"]
    print(f"ğŸ“‹ [LangGraph] Finalizing research report for: {trend}")
    
    # æœ€çµ‚çµæœã®ç”Ÿæˆ
    final_result = {
        **analysis_result,
        "research_timestamp": datetime.now().isoformat(),
        "research_type": "Gemini AI Trend Research",
        "analysis_method": "LangGraph Workflow + Gemini AI Analysis",
        "workflow_steps": [
            "1. Gemini AI Analysis",
            "2. Result Finalization"
        ]
    }
    
    state["final_result"] = final_result
    print("âœ… [LangGraph] Research report finalized")
    return state

def create_fallback_analysis_dict(trend: str, error_message: str) -> Dict[str, Any]:
    """
    åˆ†æãŒå¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æ
    """
    current_date = datetime.now()
    current_year = current_date.year
    current_month = current_date.strftime("%Yå¹´%mæœˆ")
    
    fallback_summary = f"""# ğŸ“Š {trend}ã®èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“… èª¿æŸ»æ¦‚è¦
- èª¿æŸ»æ—¥æ™‚: {current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}
- èª¿æŸ»å¯¾è±¡: {trend}
- èª¿æŸ»æ–¹æ³•: Gemini AI ã«ã‚ˆã‚‹åˆ†æ

## âš ï¸ èª¿æŸ»çŠ¶æ³
{current_month}ç¾åœ¨ã€{trend}ã«é–¢ã™ã‚‹è©³ç´°ãªåˆ†æã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚

### ğŸ” ç™ºç”Ÿã—ãŸå•é¡Œ
- ã‚·ã‚¹ãƒ†ãƒ ã®ä¸€æ™‚çš„ãªå•é¡Œ
- åˆ†æå‡¦ç†ã®ã‚¨ãƒ©ãƒ¼
- ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®åˆ¶é™

### ğŸ“‹ æ¨å¥¨äº‹é …
1. **å…¬å¼æƒ…å ±æºã®ç¢ºèª**
   - é–¢é€£ä¼æ¥­ã®å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ
   - æ¥­ç•Œå›£ä½“ã®ç™ºè¡¨
   - æ”¿åºœæ©Ÿé–¢ã®å ±å‘Šæ›¸

2. **ä¿¡é ¼ã§ãã‚‹æƒ…å ±æº**
   - ä¸»è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¡ãƒ‡ã‚£ã‚¢
   - æ¥­ç•Œå°‚é–€èªŒ
   - å­¦è¡“ç ”ç©¶æ©Ÿé–¢ã®å ±å‘Š

3. **å†èª¿æŸ»ã®å®Ÿæ–½**
   - æ™‚é–“ã‚’ãŠã„ã¦å†åº¦å®Ÿè¡Œ
   - ã‚ˆã‚Šå…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢
   - è¤‡æ•°ã®æƒ…å ±æºã§ã®ç¢ºèª

## ğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
ã‚ˆã‚Šæ­£ç¢ºãªæƒ…å ±ã‚’å¾—ã‚‹ãŸã‚ã«ã€ç›´æ¥çš„ãªæƒ…å ±æºã®ç¢ºèªã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

*æ³¨: ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯æŠ€è¡“çš„ãªå•é¡Œã«ã‚ˆã‚Šé™å®šçš„ãªå†…å®¹ã¨ãªã£ã¦ã„ã¾ã™ã€‚*"""

    return {
        "trend": trend,
        "summary": fallback_summary,
        "keywords": [trend, "èª¿æŸ»", "ã‚¨ãƒ©ãƒ¼"],
        "insights": [
            "ã‚·ã‚¹ãƒ†ãƒ ã®ä¸€æ™‚çš„ãªå•é¡ŒãŒç™ºç”Ÿ",
            "è©³ç´°ãªåˆ†æãŒå®Œäº†ã§ããªã„çŠ¶æ³",
            "ç›´æ¥çš„ãªæƒ…å ±æºã®ç¢ºèªãŒæ¨å¥¨ã•ã‚Œã‚‹"
        ],
        "latest_developments": [
            f"{current_year}å¹´ã®è©³ç´°ãªå‹•å‘åˆ†æã¯åˆ©ç”¨ã§ãã¾ã›ã‚“"
        ],
        "market_analysis": {
            "current_status": "åˆ†æãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“",
            "growth_trend": "ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã«ã‚ˆã‚Šåˆ¤å®šä¸å¯",
            "key_players": ["æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼"]
        },
        "future_outlook": [
            "æŠ€è¡“çš„ãªå•é¡Œã«ã‚ˆã‚Šå°†æ¥å±•æœ›ã®åˆ†æãŒã§ãã¾ã›ã‚“"
        ],
        "reliability_note": f"æŠ€è¡“çš„ãªå•é¡Œã«ã‚ˆã‚Šä¿¡é ¼æ€§ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã™: {error_message}",
        "error_info": error_message
    }

# LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ä½œæˆ
def create_trend_research_workflow():
    """
    LangGraphã‚’ä½¿ç”¨ã—ãŸãƒˆãƒ¬ãƒ³ãƒ‰èª¿æŸ»ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä½œæˆ
    """
    workflow = StateGraph(TrendResearchState)
    
    # ãƒãƒ¼ãƒ‰ã®è¿½åŠ 
    workflow.add_node("analyze_trend", analyze_trend_node)
    workflow.add_node("finalize_result", finalize_result_node)
    
    # ã‚¨ãƒƒã‚¸ã®è¨­å®š
    workflow.set_entry_point("analyze_trend")
    workflow.add_edge("analyze_trend", "finalize_result")
    workflow.add_edge("finalize_result", END)
    
    return workflow.compile()

# LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
trend_research_workflow = create_trend_research_workflow()
print("âœ… LangGraph trend research workflow created")

# å…¬é–‹é–¢æ•°: ãƒ•ãƒ«æ¤œç´¢
def execute_full_search(trend: str) -> Dict[str, Any]:
    """
    LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒ•ãƒ«æ¤œç´¢ã‚’å®Ÿè¡Œ
    
    Args:
        trend: æ¤œç´¢å¯¾è±¡ã®ãƒˆãƒ¬ãƒ³ãƒ‰
        
    Returns:
        æ¤œç´¢çµæœã®è¾æ›¸
    """
    try:
        print(f"ğŸ¯ [Search] Starting Gemini-based analysis for: {trend}")
        
        # LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®åˆæœŸçŠ¶æ…‹ã‚’è¨­å®š
        initial_state = TrendResearchState(
            trend=trend,
            analysis_result={},
            final_result={},
            error_message=""
        )
        
        # LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œ
        print("ğŸ”„ [Search] Executing LangGraph workflow...")
        result = trend_research_workflow.invoke(initial_state)
        
        # æœ€çµ‚çµæœã®å–å¾—
        final_result = result["final_result"]
        print(f"ğŸ‰ [Search] Gemini analysis completed for: {trend}")
        
        return final_result
        
    except Exception as e:
        print(f"âŒ [Search] Full search error: {e}")
        return create_fallback_analysis_dict(trend, f"ãƒ•ãƒ«æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")

# å…¬é–‹é–¢æ•°: ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
def get_search_health_status() -> Dict[str, Any]:
    """
    æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    
    Returns:
        ãƒ˜ãƒ«ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®è¾æ›¸
    """
    status = {
        "service": "Gemini AI Trend Research Assistant",
        "status": "operational",
        "timestamp": datetime.now().isoformat(),
        "components": {
            "gemini_ai": "operational" if llm else "unavailable",
            "langgraph_workflow": "operational" if trend_research_workflow else "unavailable",
        },
        "analysis_method": "LangGraph Workflow + Gemini AI Analysis",
        "workflow_nodes": [
            "analyze_trend",
            "finalize_result"
        ]
    }
    
    # å…¨ä½“çš„ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
    if not llm or not trend_research_workflow:
        status["status"] = "degraded"
    
    return status